{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions and tools\n",
    "### a codon table dictionary with codons as keys and amino acids as values\n",
    "### a function that makes a complementary strand of DNA\n",
    "### a function that flips a strand of DNA\n",
    "### a function that translates DNA into a sequence of amino acids\n",
    "### a function that finds instances of one dict of DNA in another\n",
    "### a function that checks for aa sequences in a protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### a codon table dictionary with codons as keys and amino acids as values\n",
    "codontable = {\n",
    "    'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "    'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "    'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "    'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
    "    'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "    'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "    'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "    'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "    'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "    'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "    'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "    'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "    'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "    'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "    'TAC':'Y', 'TAT':'Y', 'TAA':'*', 'TAG':'*',\n",
    "    'TGC':'C', 'TGT':'C', 'TGA':'*', 'TGG':'W',\n",
    "    }\n",
    "\n",
    "### a function that makes a complementary strand of DNA\n",
    "def complementary(DNA):\n",
    "    \n",
    "    DNA_comp = \"\"\n",
    "    \n",
    "    # makes the complementary sequence\n",
    "    for i in range(len(DNA)):\n",
    "        if DNA[i].lower() == \"a\":\n",
    "            DNA_comp += \"t\"\n",
    "        if DNA[i].lower() == \"t\":\n",
    "            DNA_comp += \"a\"\n",
    "        if DNA[i].lower() == \"c\":\n",
    "            DNA_comp += \"g\"\n",
    "        if DNA[i].lower() == \"g\":\n",
    "            DNA_comp += \"c\"\n",
    "    \n",
    "    # returns the complementary sequence\n",
    "    return DNA_comp.upper()\n",
    "\n",
    "### a function that flips a strand of DNA\n",
    "def flip(DNA):\n",
    "\n",
    "    DNA_flipped = \"\"\n",
    "    \n",
    "    # makes the flipped sequence\n",
    "    for i in range(len(DNA)):\n",
    "        DNA_flipped += DNA[-(i + 1)]\n",
    "    \n",
    "    # returns the flipped sequence in a DNA dictionary construct\n",
    "    return DNA_flipped\n",
    "\n",
    "### a function that translates DNA into a sequence of amino acids\n",
    "# must begin at the beginning of the coding sequence\n",
    "def translate(DNA):\n",
    "    \n",
    "    protein = \"\"\n",
    "    \n",
    "    while len(DNA) >= 3:\n",
    "        codon = DNA[0:3]\n",
    "        protein += codontable[codon.upper()]\n",
    "        DNA = DNA[3:]\n",
    "    \n",
    "    return(protein)\n",
    "\n",
    "### a function that finds instances of one dict of DNA in another\n",
    "# first entry is dict of DNA fragments (to be searched)\n",
    "# second entry is dict of DNA to be searched\n",
    "## returned is a list of lists\n",
    "# first output is a list of frags found in DNA\n",
    "# second output is a list of DNA with frags found in them\n",
    "# third output is a list of indices that tell us where frags were found in DNA\n",
    "def fraginDNA(frag, DNA):\n",
    "    frag_list = []\n",
    "    DNA_list = []\n",
    "    index = []\n",
    "    for DNAs in DNA:\n",
    "        for frags in frag:\n",
    "            if frag[frags].lower() in DNA[DNAs].lower():\n",
    "                frag_list.append(frag[frags])\n",
    "                DNA_list.append(DNA[DNAs])\n",
    "                index.append(DNA[DNAs].lower().find(frag[frags].lower()))\n",
    "    return([frag_list, DNA_list, index])\n",
    "\n",
    "### a function that checks for aa sequences in a protein\n",
    "# first entry is dictionary of amino acid sequences\n",
    "# first is a dictionary of protein (aa sequences)\n",
    "## returned is a list of lists\n",
    "# first output is a list of aa seqs found in protein\n",
    "# second output is a list of proteins with aa seqs found in them\n",
    "# third is a list of indices that tells us where frags were found in DNA\n",
    "def aainprot(aa, prot):\n",
    "    aa_list = []\n",
    "    prot_list = []\n",
    "    index = []\n",
    "    for prots in prot:\n",
    "        for aas in aa:\n",
    "            if aa[aas].upper() in prot[prots].upper():\n",
    "                aa_list.append(aa[aas])\n",
    "                prot_list.append(prot[prots])\n",
    "                index.append(prot[prots].upper().find(aa[aas].upper()))\n",
    "    return([aa_list, prot_list, index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our illegal sites\n",
    "### Restriction sites from MoClo restriction enzymes - BBF RFC 94\n",
    "### Restriction sites from BBF RFC 10\n",
    "### Restriction sites from BBF RFC 25\n",
    "### Dictionary of all of our restriction sites\n",
    "### Enterokinase protease site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the sequences in this document should be considered as 5' to 3' in direction\n",
    "\n",
    "### Restriction sites from MoClo restriction enzymes - BBF RFC 94\n",
    "bbsi_recognition_sequence   = 'gaagac'\n",
    "bsai_recognition_sequence   = 'ggtctc'\n",
    "\n",
    "### Restriction sites from BBF RFC 10\n",
    "ecori_recognition_sequence  = 'gaattc'\n",
    "psti_recognition_sequence   = 'ctgcag'\n",
    "noti_recognition_sequence   = 'gcggccgc'\n",
    "xbai_recognition_sequence   = 'tctaga'\n",
    "spei_recognition_sequence   = 'actagt'\n",
    "\n",
    "### Restriction sites from BBF RFC 25\n",
    "ngomiv_recognition_sequence = 'gccgcc'\n",
    "agei_recognition_sequence   = 'accggt'\n",
    "\n",
    "### Dictionary of all of our restriction sites\n",
    "restriction_dict = {'bbsi': bbsi_recognition_sequence, 'bsai': bsai_recognition_sequence, \n",
    "                          'ecori': ecori_recognition_sequence, 'psti': psti_recognition_sequence, \n",
    "                          'noti': noti_recognition_sequence,\n",
    "                          'xbai': xbai_recognition_sequence, 'spei': spei_recognition_sequence, \n",
    "                          'ngomiv': ngomiv_recognition_sequence, 'agei': agei_recognition_sequence}\n",
    "\n",
    "### Enterokinase protease site\n",
    "enterokinase_cleavage_sequence_aa = \"DDDDK\"\n",
    "\n",
    "proteolytic_dict = {'enterokinase_cleavage_sequence_aa': enterokinase_cleavage_sequence_aa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Parts List\n",
    "### Sec + n22 tags\n",
    "### Linkers\n",
    "### Biopolymer\n",
    "### Payload\n",
    "### Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sec + n22 tags\n",
    "input0 = \"ATG AAA TTA TTG AAA GTT GCT GCC ATT GCT GCG ATT GTT TTC AGT GGC TCT GCC CTG GCT GGG GTT GTC CCG CAA TAC GGT GGT GGA GGC AAT CAC GGG GGT GGC GGA AAT AAT TCA GGA CCT AAC\"\n",
    "sec_n22 = input0.replace(\" \", \"\")\n",
    "frontag_dict = {'sec_n22': sec_n22}\n",
    "\n",
    "### Linkers\n",
    "# long rigid linker \n",
    "input1 = \"GCAGAGGCAGCGGCAAAGGAAGCGGCTGCAAAAGAGGCCGCAGCGAAAGAAGCAGCCGCGAAGGCTCTTGAAGCGGAAGCGGCAGCCAAAGAAGCAGCGGCTAAGGAGGCAGCCGCAAAAGAAGCAGCAGCCAAGGCG\"\n",
    "rigid_linker_long = input1.replace(' ', '')\n",
    "\n",
    "# short rigid linker - DEFAULT\n",
    "rigid_linker_short = 'ggaagc'.upper()\n",
    "\n",
    "# long flexible linker\n",
    "input2 = 'GGTGGGGGGGGCTCTGGCGGTGGGGGTAGTGGCGGAGGTGGTAGT'\n",
    "flexible_linker_long = input2.replace(' ', '')\n",
    "\n",
    "# short flexible linker\n",
    "input3 = 'GGGGGTGGTGGCGGGGGAGGCGGA'\n",
    "flexible_linker_short = input3.replace(' ', '')\n",
    "\n",
    "linker_dict = {'rigid_linker_long': rigid_linker_long,\n",
    "              'rigid_linker_short': rigid_linker_short, 'flexible_linker_long': flexible_linker_long,\n",
    "              'flexible_linker_short': flexible_linker_short}\n",
    "\n",
    "### Biopolymer\n",
    "csgA = \"ATGAAACTTTTAAAAGTAGCAGCAATTGCAGCAATCGTATTCTCCGGTAGCGCTCTGGCAGGTGTTGTTCCTCAGTACGGGGGAGGCGGTAACCACGGTGGTGGCGGTAATAATAGCGGCCCAAATTCTGAGCTGAACATTTACCAGTACGGTGGCGGTAACTCTGCACTTGCTCTGCAAACTGATGCCCGTAACTCTGACTTGACTATTACCCAGCATGGTGGCGGTAATGGTGCAGATGTTGGTCAGGGCTCAGATGACAGCTCAATCGATCTGACCCAACGTGGCTTCGGTAACAGCGCTACTCTTGATCAGTGGAACGGCAAAAATTCTGAAATGACGGTTAAACAGTTCGGTGGTGGCAACGGTGCAGCAGTTGACCAGACTGCATCTAACTCCTCCGTCAACGTGACTCAGGTTGGCTTTGGTAACAACGCGACCGCTCATCAGTACTAA\"\n",
    "biopolymer_dict = {'csgA': csgA}\n",
    "\n",
    "\n",
    "### Payload\n",
    "# fungal AMPs\n",
    "payload_dict = {}\n",
    "input4 = \"GAC AGC CAC GAA GAA CGC CGT CAG GGC CGT CAC GGT CAT CAT GAG TAT GGA CGC AAG TTCCAC GAA AAA CAC CAT TCC CAC CGT GGT TAC\"\n",
    "id1 = input4.replace(\" \", \"\")\n",
    "payload_dict['id1'] = id1\n",
    "input5 = \"GAC GGG GTG AAG TTG TGT GAT GTG CCG TCA GGA ACT TGG TCG GGT CAT TGT GGC AGC TCATCA AAG TGT TCA CAG CAA TGT AAA GAC CGT GAA CAT TTC GCT TAT GGG GGT GCC TGT CACTAT CAA TTC CCT AGC GTA AAA TGC TTT TGC AAG CGC CAG TGC\"\n",
    "id2 = input5.replace(\" \", \"\")\n",
    "payload_dict['id2'] = id2\n",
    "input6 = \"AAC CTG TGC GAG CGT GCG TCT CTG ACG TGG ACG GGA AAT TGC GGA AAC ACA GGA CAC TGCGAC ACC CAG TGT CGC AAC TGG GAG TCG GCC AAA CAC GGT GCG TGT CAT AAG CGT GGT AACTGG AAA TGC TTT TGT TAC TTC GAC TGC\"\n",
    "id3 = input6.replace(\" \", \"\")\n",
    "payload_dict['id3'] = id3\n",
    "input7 = \"GGT TTG TTT GAT ATC ATT AAG AAG ATT GCT GAA TCC ATT\"\n",
    "id4 = input7.replace(\" \", \"\")\n",
    "payload_dict['id4'] = id4\n",
    "input8 = \"CGC GAA TGC AAA GCA CAA GGT CGC CAC GGT ACG TGT TTC CGC GAC GCC AAC TGT GTT CAAGTT TGT GAA AAA CAA GCC GGA TGG TCC CAC GGC GAT TGT CGC GCT CAG TTT AAG TGC AAGTGC ATT TTT GAA TGC\"\n",
    "id5 = input8.replace(\" \", \"\")\n",
    "payload_dict['id5'] = id5\n",
    "input9 = \"TTC CTG CCT ATT GTG GGC AAA CTT CTT TCG GGA TTG CTT\"\n",
    "id6 = input9.replace(\" \", \"\")\n",
    "payload_dict['id6'] = id6\n",
    "input10 = \"GCT ACA TAC AAT GGT AAG TGC TAC AAA AAG GAC AAC ATC TGC AAA TAC AAG GCG CAA TCAGGC AAG ACA GCT ATT TGC AAG TGT TAC GTG AAG AAA TGC CCG CGT GAC GGG GCT AAG TGTGAG TTT GAC TCG TAT AAG GGC AAG TGT TAC TGC\"\n",
    "id7 = input10.replace(\" \", \"\")\n",
    "payload_dict['id7'] = id7\n",
    "input11 = \"CAT CGC CAT CAG GGG CCG ATC TTT GAC ACA CGC CCG AGT CCT TTT AAC CCA AAC CAG CCC CGC CCA GGG CCC ATT TAT\"\n",
    "id8 = input11.replace(\" \", \"\")\n",
    "payload_dict['id8'] = id8\n",
    "input12 = \"GCA TTT ACA TGC CAT TGT CGC CGT AGT TGT TAT TCT ACG GAA TAT TCG TAC GGT ACT TGCACG GTC ATG GGT ATC AAT CAT CGC TTT TGC TGC CTG\"\n",
    "id9 = input12.replace(\" \", \"\")\n",
    "payload_dict['id9'] = id9\n",
    "input13 = \"CAC CCA TTG AAA CAG TAC TGG TGG CGC CCC TCG ATT\"\n",
    "id10 = input13.replace(\" \", \"\")\n",
    "payload_dict['id10'] = id10\n",
    "input14 = \"ATC TGT ATT TTC TGT TGC GGG TGC TGC CAT CGC AGC AAG TGT GGA ATG TGT TGT AAG ACA\"\n",
    "id11 = input14.replace(\" \", \"\")\n",
    "payload_dict['id11'] = id11\n",
    "input15 = \"GTA GGA GAG TGC GTT CGT GGA CGT TGT CCG AGT GGC ATG TGT TGT TCA CAG TTC GGG TACTGC GGC AAG GGT CCA AAG TAT TGT GGA CGT\"\n",
    "id12 = input15.replace(\" \", \"\")\n",
    "payload_dict['id12'] = id12\n",
    "input16 = \"CGT GGC GGA CGC CTT TGC TAC TGT CGC CGT CGT TTT TGC GTA TGT GTA GGC CGT\"\n",
    "id13 = input16.replace(\" \", \"\")\n",
    "payload_dict['id13'] = id13\n",
    "input17 = \"TGC ATC GGG AAT GGA GGC CGT TGT AAC GAA AAC GTG GGA CCT CCT TAT TGC TGC TCT GGA TTT TGT TTG CGT CAA CCT AAC CAG GGC TAC GGT GTT TGT CGC AAC CGT\"\n",
    "id14 = input17.replace(\" \", \"\")\n",
    "payload_dict['id14'] = id14\n",
    "input18 = \"CAG TGT ATC GGA AAT GGA GGC CGT TGC AAC GAA AAC GTA GGA CCG CCA TAT TGT TGT AGTGGA TTT TGC CTG CGT CAA CCG GGC CAA GGC TAT GGT TAC TGT AAG AAT CGC\"\n",
    "id15 = input18.replace(\" \", \"\")\n",
    "payload_dict['id15'] = id15\n",
    "input19 = \"CAA CAA TGT GGA CGC CAA GCA TCA GGG CGC CTG TGT GGC AAT CGC CTG TGT TGC AGT CAG TGG GGG TAT TGC GGA TCC ACC GCT TCA TAC TGC GGC GCC GGC TGT CAA TCT CAA TGT CGC TCT\"\n",
    "id16 = input19.replace(\" \", \"\")\n",
    "payload_dict['id16'] = id16\n",
    "input20 = \"CAA AAA CTG TGT GAA CGT CCC TCG GGT ACT TGG TCG GGG GTT TGC GGG AAC AAT AAT GCTTGT AAA AAC CAG TGT ATC AAT CTT GAA AAG GCC CGC CAC GGT AGT TGT AAC TAT GTG TTCCCT GCA CAT AAA TGT ATC TGT TAT TTC CCC TGT\"\n",
    "id17 = input20.replace(\" \", \"\")\n",
    "payload_dict['id17'] = id17\n",
    "input21 = \"CAA AAA TTA TGC CAA CGC CCC AGT GGG ACC TGG TCT GGG GTC TGC GGC AAC AAC AAC GCTTGC AAG AAT CAA TGT ATT CGC TTG GAG AAA GCA CGC CAC GGC TCA TGT AAC TAT GTA TTTCCC GCA CAT AAG TGC ATT TGT TAT TTC CCA TGT\"\n",
    "id18 = input21.replace(\" \", \"\")\n",
    "payload_dict['id18'] = id18\n",
    "input22 = \"GCG GAA CGC GTC GGT GCC GGG GCA CCT GTT TAT TTG\"\n",
    "id19 = input22.replace(\" \", \"\")\n",
    "payload_dict['id19'] = id19\n",
    "input23 = \"CCA GAT CCG GCA AAA ACG GCG CCT AAA AAG AAG AGT AAG AAA GCT GTT ACC\"\n",
    "id20 = input23.replace(\" \", \"\")\n",
    "payload_dict['id20'] = id20\n",
    "input24 = \"GGC CTT TTC GAT ATT ATC AAG AAG GTG GCC TCG GTT GTC GGT GGT TTA\"\n",
    "id21 = input24.replace(\" \", \"\")\n",
    "payload_dict['id21'] = id21\n",
    "input25 = \"GGC TTA TTT GAC ATC ATT AAG AAG GTT GCC TCG GTG ATC GGA GGT CTG\"\n",
    "id22 = input25.replace(\" \", \"\")\n",
    "payload_dict['id22'] = id22\n",
    "input26 = \"TAC CGT GGC GGT TAT ACT GGA CCT ATC CCC CGT CCG CCT CCC ATC GGA CGC CCG CCC TTCCGT CCG GTA TGC AAC GCT TGT TAC CGT TTG AGT GTA AGC GAT GCG CGT AAC TGT TGC ATCAAA TTC GGC TCT TGT TGT CAT TTG GTG AAA\"\n",
    "id23 = input26.replace(\" \", \"\")\n",
    "payload_dict['id23'] = id23\n",
    "input27 = \"CAG GTT TAT AAG GGC GGA TAC ACG CGC CCG ATC CCA CGC CCT CCT CCC TTC GTG CGC CCG TTG CCA GGT GGC CCC ATC GGG CCT TAT AAC GGC TGC CCT GTT AGT TGC CGT GGG ATT AGT TTC TCG CAA GCC CGT TCA TGC TGT TCT CGC TTG GGT CGC TGC TGC CAC GTA GGC AAG GGA TAC TCG\"\n",
    "id24 = input27.replace(\" \", \"\")\n",
    "payload_dict['id24'] = id24\n",
    "input28 = \"GCG TGC AAT TTC CAG TCT TGC TGG GCG ACC TGC CAG GCG CAG CAT AGT ATT TAT TTT CGCCGC GCG TTC TGC GAC CGT TCC CAG TGC AAG TGT GTA TTC GTT CGT GGG\"\n",
    "id25 = input28.replace(\" \", \"\")\n",
    "payload_dict['id25'] = id25\n",
    "input29 = \"CAT AGT TCA GGA TAC ACA CGC CCA TTA CGC AAA CCT TCA CGC CCC ATC TTC ATT CGT CCT ATT GGC TGT GAT GTA TGT TAT GGC ATT CCC TCC TCC ACG GCT CGT CTT TGT TGC TTC CGC TAT GGA GAC TGT TGT CAC TTG\"\n",
    "id26 = input29.replace(\" \", \"\")\n",
    "payload_dict['id26'] = id26\n",
    "input30 = \"TAT AGC TCG GGC TAC ACC CGC CCA CTG CCC AAG CCA TCT CGT CCC ATC TTC ATT CGC CCTATT GGT TGT GAT GTT TGT TAC GGT ATC CCA TCA TCA ACT GCC CGC TTG TGC TGC TTC CGCTAC GGT GAT TGT TGT CAT CGC\"\n",
    "id27 = input30.replace(\" \", \"\")\n",
    "payload_dict['id27'] = id27\n",
    "input31 = \"CAG GGC TGT AAG GGT CCT TAT ACC CGT CCA ATT CTG CGC CCT TAC GTC CGC CCA GTA GTC AGC TAC AAC GCT TGT ACC TTA TCC TGC CGT GGA ATT ACC ACA ACG CAA GCC CGC TCG TGT TGC ACA CGC TTA GGA CGC TGC TGT CAC GTA GCA AAG GGC TAT TCA\"\n",
    "id28 = input31.replace(\" \", \"\")\n",
    "payload_dict['id28'] = id28\n",
    "input32 = \"TCA GCA TTC ACG GTT TGG TCG GGG CCG GGC TGT AAC AAT CGT GCG GAG CGT TAT AGC AAA TGT GGG TGT TCA GCC ATC CAC CAG AAA GGG GGT TAC GAC TTC TCT TAC ACA GGG CAG ACT GCG GCG CTT TAT AAT CAA GCT GGT TGC AGC GGT GTG GCT CAC ACA CGT TTT GGT AGC TCA GCT CGT GCA TGC AAT CCG TTC GGC TGG AAA TCT ATC TTT ATC CAG TGT\"\n",
    "id29 = input32.replace(\" \", \"\")\n",
    "payload_dict['id29'] = id29\n",
    "input33 = \"TTG TGC AAC GAA CGC CCT TCA CAG ACC TGG TCT GGG AAT TGC GGA AAT ACA GCC CAC TGCGAT AAA CAG TGC CAG GAT TGG GAG AAG GCG TCT CAC GGC GCT TGT CAT AAA CGT GAA AACCAC TGG AAA TGC TTT TGT TAC TTT AAT TGC\"\n",
    "id30 = input33.replace(\" \", \"\")\n",
    "payload_dict['id30'] = id30\n",
    "input34 = \"GTC ACT TGT TTC TGT CGA CGC CGC GGT TGC GCC AGT CGT GAG CGT CAC ATT GGT TAC TGC CGC TTC GGG AAC ACA ATT TAT CGC TTG TGC TGC CGT CGT\"\n",
    "id31 = input34.replace(\" \", \"\")\n",
    "payload_dict['id31'] = id31\n",
    "input35 = \"GGG GCC GAT TTT CAG GAG TGC ATG AAA GAG CAT AGC CAA AAA CAA CAT CAG CAC CAG GGC\"\n",
    "id32 = input35.replace(\" \", \"\")\n",
    "payload_dict['id32'] = id32\n",
    "\n",
    "# chromoproteins\n",
    "payload_dict['meffblue'] = \"atgtccgttatcgcaacccagatgacgtacaaagtttatatgtcgggcaccgtgaatggtcattattttgaagtcgaaggtgatggcaaaggtcgtccgtatgaaggcgaacagaccgtcaaactgaccgtgacgaaaggcggtccgctgccgtttgcatgggatattctgagtccgcagtgccaatacggttccattccgttcaccaaatatccggaagatatcccggactacgtcaaacagagctttccggaaggtttcacgtgggaacgcattatgaactttgaagatggcgctgtgtgcaccgtttcaaacgacagctctatccaaggcaactgcttcacgtatcatgtgaaattttcgggtctgaacttcccgccgaatggcccggttatgcagaagaaaacccaaggttgggaaccgcacagtgaacgtctgtttgcgcgcggcggtatgctgatcggcaacaatttcatggccctgaaactggaaggcggtggccattatctgtgtgaatttaaaaccacgtacaaagcgaaaaaaccagtgaaaatgccgggttatcattacgttgatcgtaaactggacgtcacgaaccacaataaagactatacctcagttgaacagtgtgaaatcagcatcgcacgcaagccggtggtcgcctaataa\"\n",
    "payload_dict['tspurple'] = \"atggcgagcttggttaagaaagatatgtgtgttaagatgacgatggaaggtactgtgaacggttatcactttaagtgcgttggcgagggtgaaggcaagccgttcgagggcacgcagaacatgcgcattcgtgtcaccgagggcggtccgctgccttttgcattcgacatcctggccccgtgctgtatgtacggctctaagaccttcattaaacacgtgagcggtatcccggattactttaaagagtcctttccagagggcttcacttgggaacgtacccagatttttgaggacggtggtgttctgaccgcgcaccaagacaccagcctggaaggtaattgcctgatctataaagtgaaggttctgggtaccaatttcccggcgaatggtccggtgatgcaaaagaaaaccgcgggttgggagccgtgcgtcgagatgctgtatccgcgtgacggcgtcttgtgtggtcagagcttgatggcgctgaagtgcaccgatggcaatcatctgaccagccacctgcgcacgacgtatcgtagccgtaaaccgagcaacgccgttaacatgccggagttccattttggtgaccatcgcatcgaaatcctgaaagctgagcagggcaaattctacgaacaatacgaatcggctgtcgcacgttacagcgatgtgccggaaaaagcgacgtaataa\"\n",
    "payload_dict['fwyellow'] = \"atgacggcactgactgaaggcgcaaaactgttcgagaaagaaatcccatatatcactgagctggaaggtgacgttgaaggtatgaagtttatcatcaagggtgaaggtacaggtgacgcgagcgtcggtaaagtggatgctcagttcatttgtaccacgggcgacgttccggttccgtggagcacgctggtcaccacgctgacgtatggtgctcagtgctttgccaagtatccgcgccacattgcggatttcttcaaaagctgcatgccggaaggttacgtccaagagcgcaccatcacctttgagggtgatggcgtgttcaagacccgtgcggaagtcacctttgaaaatggcagcgtgtacaaccgtgtaaaactgaacggccagggtttcaagaaggacggccacgtgctgggcaaaaatctggagtttaactttacccctcattgtttgtacatttggggtgaccaagcgaatcatggcctgaagagcgcgttcaaaatcatgcatgagatcaccggctccaaagaggatttcattgttgccgatcacacccaaatgaataccccgattggtggtggtccggtgcacgtgccggagtaccaccacattacgtatcatgttaccctgtctaaagacgtcaccgatcaccgtgaccatttgaacattgttgaggtgatcaaggcagttgacctggagacgtaccgttaataa\"\n",
    "payload_dict['scorange'] = \"atgagcaaaatcagcgacaacgtccgcatcaaattgtacatggaaggcacggtaaataaccaccactttatgtgtgaggctgaaggcgagggtaaaccgtacgagggtacccaggaaatgaagattgaggtgattgaaggtggcccgctgccgttcgcattccatattctgagcaccagctgtatgtacggctctaaaacgttcatcaaatatgtcagcggtatccctgactatttcaagcagtccttcccggaaggtttcacctgggagcgtacgactacctacgaggatggcggttttctgacggcgcatcaagacaccagcttggacggcgattgcctggtttacaaggttaagatcctgggtaataactttccggcggatggtccggttatgcagaataaagcagagcgctgggaaccggccaccgagattctgtatgaggtggatggtgtgctgcgtggccaaaccctgatggcgttgaagtgcgcggacggtaaccatctgacctgccacctgcgtaccacgtatcgtagcaagaaaccggcgtcggccctgaagatgccaggttttcactttggtgatcaccgcatcgagattatggaagaagttgagaaaggcaagtgttacaagcaatatgaagccgcggtcgcacgttactgcgacgcggctccgagcaaactgggtcaccattaataa\"\n",
    "\n",
    "# adhesives\n",
    "input36 = \"GCC GAT TAC TAT GGT CCC AAA TAC GGA CCT CCG CGC CGC TAC GGG GGT GGA AAT TAC AAT CGT TAT GGG CGT CGT TAC GGA GGA TAC AAG GGA TGG AAT AAC GGT TGG AAA CGC GGG CGC TGG GGA CGT AAG TAT TAC\"\n",
    "payload_dict['mfp3'] = input36.replace(\" \", \"\")\n",
    "input37 = \"TCT TCC GAG GAG TAT AAA GGT GGC TAC TAT CCC GGA AAC ACT TAC CAC TAC CAT TCG GGA GGT AGT TAT CAT GGC TCG GGC TAC CAC GGG GGA TAC AAG GGA AAA TAT TAT GGG AAA GCA AAG AAG TAT TAT TAC AAA TAC AAG AAC TCG GGA AAG TAC AAG TAC CTG AAG AAG GCC CGT AAA TAT CAT CGT AAA GGG TAT AAG AAA TAT TAT GGG GGA GGA TCT TCA\"\n",
    "payload_dict['mfp5'] = input37.replace(\" \", \"\")\n",
    "\n",
    "### Tag\n",
    "tag_dict = {}\n",
    "input38 = \"CAT CAT CAT CAT CAC CAC\"\n",
    "tag_dict['his'] = input38.replace(\" \", \"\")\n",
    "input39 = \"GAG CCC TTA CAG TTA AAG ATG\"\n",
    "tag_dict['gpb'] = input39.replace(\" \", \"\")\n",
    "input40 = \"GAC TAC AAA GAT GAC GAT GAT AAA\"\n",
    "tag_dict['flag'] = input40.replace(\" \", \"\")\n",
    "input41 = \"CAC AGT AGC TAC TGG TAT GCA TTT AAT AAC AAG ACG\"\n",
    "tag_dict['cnbp'] = input41.replace(\" \", \"\")\n",
    "input42 = \"GCC TAC TCC TCT GGT GCG CCT CCG ATG CCT CCC TTT\"\n",
    "tag_dict['a3'] = input42.replace(\" \", \"\")\n",
    "input43 = \"AAT CCC TAC CAC CCT ACG ATT CCA CAG TCA GTA CAC\"\n",
    "tag_dict['clp12'] = input43.replace(\" \", \"\")\n",
    "input44 = \"CCC CCT CCC TGG TTG CCA TAC ATG CCC CCA TGG AGT\"\n",
    "tag_dict['qbp1'] = input44.replace(\" \", \"\")\n",
    "input45 = \"GCA CAC ATT GTT ATG GTT GAT GCC TAC AAG CCA ACG AAG\"\n",
    "tag_dict['spytag'] = input45.replace(\" \", \"\")\n",
    "input46 = \"TGT GGA CCT GCT GGG GAT TCG TCC GGA GTG GAC AGT CGT TCC GTG GGA CCT TGC\"\n",
    "tag_dict['ct43'] = input46.replace(\" \", \"\")\n",
    "input47 = \"AAG TGC ACC TCA GAT CAG GAC GAA CAG TTC ATT CCG AAG GGG TGC TCA AAA GGG TCA GGT GGT TCT GGC\"\n",
    "tag_dict['mbd'] = input47.replace(\" \", \"\")\n",
    "input48 = \"GAT ACG GCC TCG GAC GCA GCG GCT GCT GCC GCT CTG ACA GCT GCC AAC GCG AAG GCC GCG GCA GAA CTG ACG GCC GCG AAT GCG GCT GCC GCA GCT GCT GCC ACG GCA CGT\"\n",
    "tag_dict['afp8'] = input48.replace(\" \", \"\")\n",
    "input49 = \"GGA GGG ACG ATT TGG ACA GGA AAG GGA CTT GGC CTT GGA CTG GGG TTG GGC CTT GGT GCC TGG GGG CCA ATC ATT CTG GGG GTA GTG GGC GCT GGG GCA GTT TAT GCT TAT ATG AAG TCT CGT GAT ATT GAG TCT GCC CAG TCC GAC GAG GAG GTT GAA TTG CGC GAC GCC TTG GCC\"\n",
    "tag_dict['mms6'] = input49.replace(\" \", \"\")\n",
    "input50 = \"GGT GCG ATG GTA GAT ACT TTG TCC GGC CTG TCT AGT GAG CAA GGT CAG TCA GGG GAT ATG ACC ATC GAG GAG GAT AGT GCG ACC CAC ATT AAG TTT TCA AAG CGT GAC GAA GAT GGC AAG GAG CTT GCG GGA GCC ACA ATG GAA TTG CGC GAT AGT TCA GGA AAG ACA ATT TCA ACA TGG ATC TCT GAT GGG CAG GTC AAA GAC TTC TAC TTG TAT CCA GGA AAG TAT ACG TTT GTC GAA ACC GCA GCC CCA GAT GGC TAC GAG GTT GCG ACG GCT ATT ACA TTT ACA GTC AAC GAA CAA GGG CAG GTA ACT GTT AAT GGG AAG GCT ACG AAG GGC GAC GCT CAT ATC\"\n",
    "tag_dict['spycatcher'] = input50.replace(\" \", \"\")\n",
    "input51 = \"GCA GCC AAC GAC GAA AAT TAC GCC CTT GCT GCA\"\n",
    "tag_dict['ssssra'] = input51.replace(\" \", \"\")\n",
    "input52 = \"AAT AAT CAT TAC TTG CCA CGT\"\n",
    "tag_dict['hbp7'] = input52.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for Illegal Sites\n",
    "### Sec + n22\n",
    "### Linkers\n",
    "### Biopolymer\n",
    "### Payloads\n",
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no restriction sites in front tags\n",
      "There are no restriction sites in front tag complements\n",
      "There are no restriction sites in linkers\n",
      "There are no restriction sites in linker complements\n",
      "There are no restriction sites in biopolymers\n",
      "There are no restriction sites in biopolymer complements\n",
      "There are no restriction sites in payloads\n",
      "There are no restriction sites in payload complements\n",
      "There are no restriction sites in tags\n",
      "There are no restriction sites in tag complements\n"
     ]
    }
   ],
   "source": [
    "### Sec + n22\n",
    "frontagdigestlist = fraginDNA(restriction_dict, frontag_dict)\n",
    "if len(frontagdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in front tags\")\n",
    "else:\n",
    "    for i in range(len(frontagdigestlist[0])):\n",
    "        print(frontagdigestlist[0][i] + \" is in \" + frontagdigestlist[1][i] + \" at index \" + str(frontagdigestlist[2][i]))\n",
    "\n",
    "comp_frontag_dict = {}\n",
    "for frontag in frontag_dict:\n",
    "    comp_frontag_dict[frontag] = flip(complementary(frontag_dict[frontag]))\n",
    "compfrontagdigestlist = fraginDNA(restriction_dict, comp_frontag_dict)\n",
    "if len(compfrontagdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in front tag complements\")\n",
    "else:\n",
    "    for i in range(len(compfrontagdigestlist[0])):\n",
    "        print(compfrontagdigestlist[0][i] + \" is in \" + compfrontagdigestlist[1][i] + \" at index \" + \n",
    "              str(compfrontagdigestlist[2][i]))\n",
    "\n",
    "### Linkers\n",
    "linkerdigestlist = fraginDNA(restriction_dict, linker_dict)\n",
    "if len(linkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in linkers\")\n",
    "else:\n",
    "    for i in range(len(linkerdigestlist[0])):\n",
    "        print(linkerdigestlist[0][i] + \" is in \" + linkerdigestlist[1][i] + \" at index \" + str(linkerdigestlist[2][i]))\n",
    "\n",
    "comp_linker_dict = {}\n",
    "for linker in linker_dict:\n",
    "    comp_linker_dict[linker] = flip(complementary(linker_dict[linker]))\n",
    "complinkerdigestlist = fraginDNA(restriction_dict, comp_linker_dict)\n",
    "if len(complinkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in linker complements\")\n",
    "else:\n",
    "    for i in range(len(complinkerdigestlist[0])):\n",
    "        print(complinkerdigestlist[0][i] + \" is in \" + complinkerdigestlist[1][i] + \" at index \" + \n",
    "              str(complinkerdigestlist[2][i]))\n",
    "        \n",
    "### biopolymer\n",
    "biopolymerdigestlist = fraginDNA(restriction_dict, biopolymer_dict)\n",
    "if len(biopolymerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in biopolymers\")\n",
    "else:\n",
    "    for i in range(len(biopolymerdigestlist[0])):\n",
    "        print(biopolymerdigestlist[0][i] + \" is in \" + biopolymerdigestlist[1][i] + \" at index \" + str(biopolymerdigestlist[2][i]))\n",
    "\n",
    "comp_biopolymer_dict = {}\n",
    "for biopolymer in biopolymer_dict:\n",
    "    comp_biopolymer_dict[biopolymer] = flip(complementary(biopolymer_dict[biopolymer]))\n",
    "compbiopolymerdigestlist = fraginDNA(restriction_dict, comp_biopolymer_dict)\n",
    "if len(compbiopolymerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in biopolymer complements\")\n",
    "else:\n",
    "    for i in range(len(compbiopolymerdigestlist[0])):\n",
    "        print(compbiopolymerdigestlist[0][i] + \" is in \" + compbiopolymerdigestlist[1][i] + \" at index \" + \n",
    "              str(compbiopolymerdigestlist[2][i]))\n",
    "\n",
    "### payloads\n",
    "payloaddigestlist = fraginDNA(restriction_dict, payload_dict)\n",
    "if len(payloaddigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in payloads\")\n",
    "else:\n",
    "    for i in range(len(payloaddigestlist[0])):\n",
    "        print(payloaddigestlist[0][i] + \" is in \" + payloaddigestlist[1][i] + \" at index \" + str(payloaddigestlist[2][i]))\n",
    "\n",
    "comp_payload_dict = {}\n",
    "for payload in payload_dict:\n",
    "    comp_payload_dict[payload] = flip(complementary(payload_dict[payload]))\n",
    "comppayloaddigestlist = fraginDNA(restriction_dict, comp_payload_dict)\n",
    "if len(comppayloaddigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in payload complements\")\n",
    "else:\n",
    "    for i in range(len(comppayloaddigestlist[0])):\n",
    "        print(comppayloaddigestlist[0][i] + \" is in \" + comppayloaddigestlist[1][i] + \" at index \" + \n",
    "              str(comppayloaddigestlist[2][i]))\n",
    "\n",
    "### tags\n",
    "tagdigestlist = fraginDNA(restriction_dict, tag_dict)\n",
    "if len(tagdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in tags\")\n",
    "else:\n",
    "    for i in range(len(tagdigestlist[0])):\n",
    "        print(tagdigestlist[0][i] + \" is in \" + tagdigestlist[1][i] + \" at index \" + str(tagdigestlist[2][i]))\n",
    "\n",
    "comp_tag_dict = {}\n",
    "for tag in tag_dict:\n",
    "    comp_tag_dict[tag] = flip(complementary(tag_dict[tag]))\n",
    "comptagdigestlist = fraginDNA(restriction_dict, comp_tag_dict)\n",
    "if len(comptagdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in tag complements\")\n",
    "else:\n",
    "    for i in range(len(comptagdigestlist[0])):\n",
    "        print(comptagdigestlist[0][i] + \" is in \" + comptagdigestlist[1][i] + \" at index \" + \n",
    "              str(comptagdigestlist[2][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for proteolytic sites\n",
    "### Front tags\n",
    "### Linkers\n",
    "### Biopolymer\n",
    "### Payloads\n",
    "### Tags\n",
    "So, the tag['flag'] tag has an enterokinase cleavage site. I'm gonna let this be for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no proteolytic sites in frontags\n",
      "There are no proteolytic sites in linkers\n",
      "There are no proteolytic sites in biopolymers\n",
      "There are no proteolytic sites in payloads\n",
      "DDDDK is in DYKDDDDK at index 3\n"
     ]
    }
   ],
   "source": [
    "### front tags\n",
    "aa_frontag_dict = {}\n",
    "for frontag in frontag_dict:\n",
    "    aa_frontag_dict[frontag] = translate(frontag_dict[frontag])\n",
    "frontagprotdigestlist = aainprot(proteolytic_dict, aa_frontag_dict)\n",
    "if len(frontagprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in frontags\")\n",
    "else:\n",
    "    for i in range(len(frontagprotdigestlist[0])):\n",
    "        print(frontagprotdigestlist[0][i] + \" is in \" + frontagprotdigestlist[1][i] + \" at index \" + \n",
    "             str(frontagprotdigestlist[2][i]))\n",
    "\n",
    "### linkers\n",
    "aa_linker_dict = {}\n",
    "for linker in linker_dict:\n",
    "    aa_linker_dict[linker] = translate(linker_dict[linker])\n",
    "linkerprotdigestlist = aainprot(proteolytic_dict, aa_linker_dict)\n",
    "if len(linkerprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in linkers\")\n",
    "else:\n",
    "    for i in range(len(linkerprotdigestlist[0])):\n",
    "        print(linkerprotdigestlist[0][i] + \" is in \" + linkerprotdigestlist[1][i] + \" at index \" + \n",
    "             str(linkerprotdigestlist[2][i]))\n",
    "\n",
    "### biopolymer\n",
    "aa_biopolymer_dict = {}\n",
    "for biopolymer in biopolymer_dict:\n",
    "    aa_biopolymer_dict[biopolymer] = translate(biopolymer_dict[biopolymer])\n",
    "biopolymerprotdigestlist = aainprot(proteolytic_dict, aa_biopolymer_dict)\n",
    "if len(biopolymerprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in biopolymers\")\n",
    "else:\n",
    "    for i in range(len(biopolymerprotdigestlist[0])):\n",
    "        print(biopolymerprotdigestlist[0][i] + \" is in \" + biopolymerprotdigestlist[1][i] + \" at index \" + \n",
    "             str(biopolymerprotdigestlist[2][i]))\n",
    "        \n",
    "### payloads\n",
    "aa_payload_dict = {}\n",
    "for payload in payload_dict:\n",
    "    aa_payload_dict[payload] = translate(payload_dict[payload])\n",
    "payloadprotdigestlist = aainprot(proteolytic_dict, aa_payload_dict)\n",
    "if len(payloadprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in payloads\")\n",
    "else:\n",
    "    for i in range(len(payloadprotdigestlist[0])):\n",
    "        print(payloadprotdigestlist[0][i] + \" is in \" + payloadprotdigestlist[1][i] + \" at index \" + \n",
    "             str(payloadprotdigestlist[2][i]))\n",
    "        \n",
    "### tag\n",
    "aa_tag_dict = {}\n",
    "for tag in tag_dict:\n",
    "    aa_tag_dict[tag] = translate(tag_dict[tag])\n",
    "tagprotdigestlist = aainprot(proteolytic_dict, aa_tag_dict)\n",
    "if len(tagprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in tags\")\n",
    "else:\n",
    "    for i in range(len(tagprotdigestlist[0])):\n",
    "        print(tagprotdigestlist[0][i] + \" is in \" + tagprotdigestlist[1][i] + \" at index \" + \n",
    "             str(tagprotdigestlist[2][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the library\n",
    "\n",
    "Go the following link for a more detailed explanation of our library assembly method - this is for libraries 1-10:\n",
    "https://docs.google.com/document/d/1D9qJ49pugpkksllmeUM2MvXzJJ-jDwx4-HqbrwazKPw/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subparts for our final ultramers\n",
    "### Cut sites\n",
    "### Start and stop codons\n",
    "### BbsI and BbsI'\n",
    "### NN sequences (two base buffer)\n",
    "### Main part sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cut sites\n",
    "# cut sites are in order of position\n",
    "cut_dict = {'A': 'ggggag', 'B': 'tactct', 'C': 'tcaatg', 'D': 'aggtcg', 'E': 'gggctt', 'F': 'cgctcc', 'G': 'agtgcc', 'H': 'actagc'}\n",
    "\n",
    "### Start and stop codons\n",
    "start = \"atg\"\n",
    "stop = \"taa\"\n",
    "\n",
    "### BbsI and BbsI'\n",
    "BbsI = \"GAAGAC\"\n",
    "BbsIprime = \"GTCTTC\"\n",
    "\n",
    "### NN sequences (two base buffer)\n",
    "NN = \"aa\"\n",
    "\n",
    "### Main part sequences\n",
    "frontag_dict\n",
    "linker_dict\n",
    "biopolymer_dict\n",
    "payload_dict\n",
    "tag_dict\n",
    "\n",
    "print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1_pos1 = {}\n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib1_pos1[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "dict1 = [lib1_pos1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curli - tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib2_pos1 = {}\n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib2_pos1[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "lib2_pos2 = {}\n",
    "for tag in tag_dict:\n",
    "    lib2_pos2[tag] = (BbsI + NN + cut_dict['D'] + tag_dict[tag] + (2*stop) + cut_dict['E'] + NN + BbsIprime).upper()\n",
    "\n",
    "dict2 = [lib2_pos1, lib2_pos2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curli - linker - payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib3_pos1 = {}\n",
    "lib3_pos2 = {}\n",
    "lib3_pos3 = {}\n",
    "dict3 = [lib3_pos1, lib3_pos2, lib3_pos3]\n",
    "\n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib3_pos1[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib3_pos2[linker] = (BbsI + NN + cut_dict['D'] + linker_dict[linker] + cut_dict['E'] + NN + BbsIprime).upper()\n",
    "\n",
    "for payload in payload_dict:\n",
    "    lib3_pos3[payload] = (BbsI + cut_dict['E'] + payload_dict[payload] + (2*stop) + cut_dict['F'] + BbsIprime).upper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curli - linker - payload - tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib4_pos1 = {}\n",
    "lib4_pos2 = {}\n",
    "lib4_pos3 = {}\n",
    "lib4_pos4 = {}\n",
    "dict4 = [lib4_pos1, lib4_pos2, lib4_pos3, lib4_pos4]\n",
    "\n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib4_pos1[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib4_pos2[linker] = (BbsI + NN + cut_dict['D'] + linker_dict[linker] + cut_dict['E'] + NN + BbsIprime).upper()\n",
    "\n",
    "for payload in payload_dict:\n",
    "    lib4_pos3[payload] = (BbsI + cut_dict['E'] + payload_dict[payload] + cut_dict['F'] + BbsIprime).upper()\n",
    "\n",
    "for tag in tag_dict:\n",
    "    lib4_pos4[tag] = (BbsI + NN + cut_dict['F'] + tag_dict[tag] + (2*stop) + cut_dict['G'] + NN + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec-n22 - linker - biopolymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib5_pos1 = {}\n",
    "lib5_pos2 = {}\n",
    "lib5_pos3 = {}\n",
    "dict5 = [lib5_pos1, lib5_pos2, lib5_pos3]\n",
    "\n",
    "for frontag in frontag_dict:\n",
    "    lib5_pos1[frontag] = (BbsI + cut_dict['A'] + frontag_dict[frontag] + cut_dict['B'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib5_pos2[linker] = (BbsI + NN + cut_dict['B'] + linker_dict[linker] + cut_dict['C'] + NN + BbsIprime).upper()\n",
    "    \n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib5_pos3[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer] + cut_dict['D'] + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec-n22-linker-biopolymer-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib6_pos1 = {}\n",
    "lib6_pos2 = {}\n",
    "lib6_pos3 = {}\n",
    "lib6_pos4 = {}\n",
    "dict6 = [lib6_pos1, lib6_pos2, lib6_pos3, lib6_pos4]\n",
    "\n",
    "for frontag in frontag_dict:\n",
    "    lib6_pos1[frontag] = (BbsI + cut_dict['A'] + frontag_dict[frontag] + cut_dict['B'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib6_pos2[linker] = (BbsI + NN + cut_dict['B'] + linker_dict[linker] + cut_dict['C'] + NN + BbsIprime).upper()\n",
    "    \n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib6_pos3[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "for tag in tag_dict:\n",
    "    lib6_pos4[tag] = (BbsI + NN + cut_dict['D'] + tag_dict[tag] + (2*stop) + cut_dict['E'] + NN + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec-n22-linker-biopolymer-linker-payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib7_pos1 = {}\n",
    "lib7_pos2 = {}\n",
    "lib7_pos3 = {}\n",
    "lib7_pos4 = {}\n",
    "lib7_pos5 = {}\n",
    "dict7 = [lib7_pos1, lib7_pos2, lib7_pos3, lib7_pos4, lib7_pos5]\n",
    "\n",
    "for frontag in frontag_dict:\n",
    "    lib7_pos1[frontag] = (BbsI + cut_dict['A'] + frontag_dict[frontag] + cut_dict['B'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib7_pos2[linker] = (BbsI + NN + cut_dict['B'] + linker_dict[linker] + cut_dict['C'] + NN + BbsIprime).upper()\n",
    "    \n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib7_pos3[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib7_pos4[linker] = (BbsI + NN + cut_dict['D'] + linker_dict[linker] + cut_dict['E'] + NN + BbsIprime).upper()\n",
    "\n",
    "for payload in payload_dict:\n",
    "    lib7_pos5[payload] = (BbsI + cut_dict['E'] + payload_dict[payload] + (2*stop) + cut_dict['F'] + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec-n22-linker-biopolymer-linker-payload-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib8_pos1 = {}\n",
    "lib8_pos2 = {}\n",
    "lib8_pos3 = {}\n",
    "lib8_pos4 = {}\n",
    "lib8_pos5 = {}\n",
    "lib8_pos6 = {}\n",
    "dict8 = [lib8_pos1, lib8_pos2, lib8_pos3, lib8_pos4, lib8_pos5, lib8_pos6]\n",
    "\n",
    "for frontag in frontag_dict:\n",
    "    lib8_pos1[frontag] = (BbsI + cut_dict['A'] + frontag_dict[frontag] + cut_dict['B'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib8_pos2[linker] = (BbsI + NN + cut_dict['B'] + linker_dict[linker] + cut_dict['C'] + NN + BbsIprime).upper()\n",
    "    \n",
    "for biopolymer in biopolymer_dict:\n",
    "    lib8_pos3[biopolymer] = (BbsI + cut_dict['C'] + biopolymer_dict[biopolymer][:-3] + cut_dict['D'] + BbsIprime).upper()\n",
    "\n",
    "for linker in linker_dict:\n",
    "    lib8_pos4[linker] = (BbsI + NN + cut_dict['D'] + linker_dict[linker] + cut_dict['E'] + NN + BbsIprime).upper()\n",
    "\n",
    "for payload in payload_dict:\n",
    "    lib8_pos5[payload] = (BbsI + cut_dict['E'] + payload_dict[payload] + cut_dict['F'] + BbsIprime).upper()\n",
    "\n",
    "for tag in tag_dict:\n",
    "    lib8_pos6[tag] = (BbsI + NN + cut_dict['F'] + tag_dict[tag] + (2*stop) + cut_dict['G'] + NN + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries 9 and 10 are the same as 7 and 8, except for the payload, but I have all the payloads in a single library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving these sequences into csv form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w') as output:\n",
    "    writer = csv.writer(output)\n",
    "    writer.writerow(['library 1', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict1:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "        \n",
    "    writer.writerow(['library 2', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict2:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "        \n",
    "    writer.writerow(['library 3', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict3:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "    \n",
    "    writer.writerow(['library 4', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict4:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "    \n",
    "    writer.writerow(['library 5', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict5:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "        \n",
    "    writer.writerow(['library 6', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict6:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "    \n",
    "    writer.writerow(['library 7', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict7:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])\n",
    "    \n",
    "    writer.writerow(['library 8', ''])\n",
    "    writer.writerow([])\n",
    "    for position in dict8:\n",
    "        for key, value in position.items():\n",
    "            writer.writerow([key, value])\n",
    "        writer.writerow([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
