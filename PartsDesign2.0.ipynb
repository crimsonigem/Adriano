{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions and tools\n",
    "### a codon table dictionary with codons as keys and amino acids as values\n",
    "### a function that makes a complementary strand of DNA\n",
    "### a function that flips a strand of DNA\n",
    "### a function that translates DNA into a sequence of amino acids\n",
    "### a function that finds instances of one dict of DNA in another\n",
    "### a function that checks for aa sequences in a protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a codon table dictionary with codons as keys and amino acids as values\n",
    "codontable = {\n",
    "    'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "    'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "    'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "    'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
    "    'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "    'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "    'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "    'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "    'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "    'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "    'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "    'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "    'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "    'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "    'TAC':'Y', 'TAT':'Y', 'TAA':'*', 'TAG':'*',\n",
    "    'TGC':'C', 'TGT':'C', 'TGA':'*', 'TGG':'W',\n",
    "    }\n",
    "\n",
    "### a function that makes a complementary strand of DNA\n",
    "def complementary(DNA):\n",
    "    \n",
    "    DNA_comp = \"\"\n",
    "    \n",
    "    # makes the complementary sequence\n",
    "    for i in range(len(DNA)):\n",
    "        if DNA[i].lower() == \"a\":\n",
    "            DNA_comp += \"t\"\n",
    "        if DNA[i].lower() == \"t\":\n",
    "            DNA_comp += \"a\"\n",
    "        if DNA[i].lower() == \"c\":\n",
    "            DNA_comp += \"g\"\n",
    "        if DNA[i].lower() == \"g\":\n",
    "            DNA_comp += \"c\"\n",
    "    \n",
    "    # returns the complementary sequence\n",
    "    return DNA_comp.upper()\n",
    "\n",
    "### a function that flips a strand of DNA\n",
    "def flip(DNA):\n",
    "\n",
    "    DNA_flipped = \"\"\n",
    "    \n",
    "    # makes the flipped sequence\n",
    "    for i in range(len(DNA)):\n",
    "        DNA_flipped += DNA[-(i + 1)]\n",
    "    \n",
    "    # returns the flipped sequence in a DNA dictionary construct\n",
    "    return DNA_flipped\n",
    "\n",
    "### a function that translates DNA into a sequence of amino acids\n",
    "# must begin at the beginning of the coding sequence\n",
    "def translate(DNA):\n",
    "    \n",
    "    protein = \"\"\n",
    "    \n",
    "    while len(DNA) >= 3:\n",
    "        codon = DNA[0:3]\n",
    "        protein += codontable[codon.upper()]\n",
    "        DNA = DNA[3:]\n",
    "    \n",
    "    return(protein)\n",
    "\n",
    "### a function that finds instances of one dict of DNA in another\n",
    "# first entry is dict of DNA fragments (to be searched)\n",
    "# second entry is dict of DNA to be searched\n",
    "## returned is a list of lists\n",
    "# first output is a list of frags found in DNA\n",
    "# second output is a list of DNA with frags found in them\n",
    "# third output is a list of indices that tell us where frags were found in DNA\n",
    "def fraginDNA(frag, DNA):\n",
    "    frag_list = []\n",
    "    DNA_list = []\n",
    "    index = []\n",
    "    for DNAs in DNA:\n",
    "        for frags in frag:\n",
    "            if frag[frags].lower() in DNA[DNAs].lower():\n",
    "                frag_list.append(frag[frags])\n",
    "                DNA_list.append(DNA[DNAs])\n",
    "                index.append(DNA[DNAs].lower().find(frag[frags].lower()))\n",
    "    return([frag_list, DNA_list, index])\n",
    "\n",
    "### a function that checks for aa sequences in a protein\n",
    "# first entry is dictionary of amino acid sequences\n",
    "# first is a dictionary of protein (aa sequences)\n",
    "## returned is a list of lists\n",
    "# first output is a list of aa seqs found in protein\n",
    "# second output is a list of proteins with aa seqs found in them\n",
    "# third is a list of indices that tells us where frags were found in DNA\n",
    "def aainprot(aa, prot):\n",
    "    aa_list = []\n",
    "    prot_list = []\n",
    "    index = []\n",
    "    for prots in prot:\n",
    "        for aas in aa:\n",
    "            if aa[aas].upper() in prot[prots].upper():\n",
    "                aa_list.append(aa[aas])\n",
    "                prot_list.append(prot[prots])\n",
    "                index.append(prot[prots].upper().find(aa[aas].upper()))\n",
    "    return([aa_list, prot_list, index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our illegal sites\n",
    "### Restriction sites from MoClo restriction enzymes - BBF RFC 94\n",
    "### Restriction sites from BBF RFC 10\n",
    "### Restriction sites from BBF RFC 25\n",
    "### Dictionary of all of our restriction sites\n",
    "### Enterokinase protease site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all of the sequences in this document should be considered as 5' to 3' in direction\n",
    "\n",
    "### Restriction sites from MoClo restriction enzymes - BBF RFC 94\n",
    "bbsi_recognition_sequence   = 'gaagac'\n",
    "bsai_recognition_sequence   = 'ggtctc'\n",
    "\n",
    "### Restriction sites from BBF RFC 10\n",
    "ecori_recognition_sequence  = 'gaattc'\n",
    "psti_recognition_sequence   = 'ctgcag'\n",
    "noti_recognition_sequence   = 'gcggccgc'\n",
    "xbai_recognition_sequence   = 'tctaga'\n",
    "spei_recognition_sequence   = 'actagt'\n",
    "\n",
    "### Restriction sites from BBF RFC 25\n",
    "ngomiv_recognition_sequence = 'gccgcc'\n",
    "agei_recognition_sequence   = 'accggt'\n",
    "\n",
    "### Dictionary of all of our restriction sites\n",
    "restriction_dict = {'bbsi': bbsi_recognition_sequence, 'bsai': bsai_recognition_sequence, \n",
    "                          'ecori': ecori_recognition_sequence, 'psti': psti_recognition_sequence, \n",
    "                          'noti': noti_recognition_sequence,\n",
    "                          'xbai': xbai_recognition_sequence, 'spei': spei_recognition_sequence, \n",
    "                          'ngomiv': ngomiv_recognition_sequence, 'agei': agei_recognition_sequence}\n",
    "\n",
    "### Enterokinase protease site\n",
    "enterokinase_cleavage_sequence_aa = \"DDDDK\"\n",
    "\n",
    "proteolytic_dict = {'enterokinase_cleavage_sequence_aa': enterokinase_cleavage_sequence_aa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our parts list\n",
    "### Making a Non-Cleavable Linker dictionary\n",
    "### Making Cleavable Linker dictionary\n",
    "### Making AMP dictionary\n",
    "### Making additional protein domain dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Making a Non-Cleavable Linker dictionary\n",
    "\n",
    "# long rigid linker \n",
    "input = \"GCAGAGGCAGCGGCAAAGGAAGCGGCTGCAAAAGAGGCCGCAGCGAAAGAAGCAGCCGCGAAGGCTCTTGAAGCGGAAGCGGCAGCCAAAGAAGCAGCGGCTAAGGAGGCAGCCGCAAAAGAAGCAGCAGCCAAGGCG\"\n",
    "rigid_linker_long = input.replace(' ', '')\n",
    "\n",
    "# short rigid linker - DEFAULT\n",
    "rigid_linker_short = 'ggaagc'.upper()\n",
    "\n",
    "# long flexible linker\n",
    "input2 = 'GGTGGGGGGGGCTCTGGCGGTGGGGGTAGTGGCGGAGGTGGTAGT'\n",
    "flexible_linker_long = input2.replace(' ', '')\n",
    "\n",
    "# short flexible linker\n",
    "input3 = 'GGGGGTGGTGGCGGGGGAGGCGGA'\n",
    "flexible_linker_short = input3.replace(' ', '')\n",
    "\n",
    "linker_dict = {'rigid_linker_long': rigid_linker_long,\n",
    "              'rigid_linker_short': rigid_linker_short, 'flexible_linker_long': flexible_linker_long,\n",
    "              'flexible_linker_short': flexible_linker_short}\n",
    "\n",
    "### Making Cleavable Linker dictionary\n",
    "enterokinase_recognition_site = 'GGTGGTGGGGGAGGAGGTGGCGGGGACGATGACGACAAA'\n",
    "clinker_dict = {'enterokinase_recognition_site': enterokinase_recognition_site}\n",
    "\n",
    "### Making AMP dictionary\n",
    "# amps, id's should correspond to the id's in the parts Google sheets document in the shared folder\n",
    "id14 = \"GGTTCATGCAGTTGTTCGGGCACCATCAGCCCCTACGGCCTGCGCACTTGTCGCGCGACTAAGACGAAACCATCGCATCCGACCACGAAAGAAACACATCCGCAGACGCTTCCGACG\"\n",
    "id15 = \"TAT GTC AGT TGC TTG TTT CGT GGT GCC CGT TGC CGT GTA TAT TCG GGT CGT TCA TGT TGC TTT GGC TAC TAC TGC CGT CGT GAC TTT CCT GGG TCG ATC TTC GGG ACT TGT TCC CGT CGC AAC TTT\"\n",
    "id16 = \"GCA CGT TCC TAC GGC AAT GGG GTA TAT TGC AAT AAC AAG AAG TGT TGG GTG AAT CGC GGG GAG GCG ACT CAG AGC ATC ATT GGA GGT ATG ATC TCA GGG TGG GCG AGC GGG TTA GCG GGA ATG\"\n",
    "id17 = \"CAAGTTTACAAGGGCGGATACACACGTCCAATTCCTCGTCCCCCCCCATTCGTCCGTCCTCTTCCTGGTGGCCCGATTGGCCCGTACAATGGATGTCCGGTGTCGTGCCGTGGAATTTCGTTCAGCCAAGCCCGTAGCTGTTGCTCCCGTCTGGGACGTTGTTGCCATGTTGGAAAGGGGTATTCT\"\n",
    "id18 = \"AAA CCA GCT TGG TGC TGG TAC ACA CTG GCA ATG TGT GGG GCC GGG TAC GAT TCG GGC ACT TGT GAT TAT ATG TAT AGC CAC TGC TTC GGA GTA AAG CAC TCA TCG GGG GGA GGT GGG TCT TAC CAC TGC\"\n",
    "id19 = \"GCC ACC TGC GAC TTG CTG TCG ATT AGC ACC CCG TGG GGC AGT GTC AAC CAC GCT GCG TGT GCT GCC CAC TGC TTG GCC CTT AAT CGC GGT TTT CGT GGC GGT TAT TGC TCC TCA AAG GCG GTG TGT ACT TGT CGC AAG\"\n",
    "id20 = \"CAC CGT CAC CAA GGG CCA ATT TTC GAC ACT CGT CCA TCA CCC TTT AAC CCA AAT CAG CCC CGC CCG GGG CCC ATT TAT\"\n",
    "id21 = \"GGTATCTGGAGCTCAATCAAGAATTTAGCGTCAAAAGCCTGGAATAGCGACATCGGCCAGTCACTGCGTAACAAAGCGGCGGGCGCAATCAACAAGTTTGTAGCAGACAAAATTGGCGTTACCCCATCGCAGGCAGCATCG\"\n",
    "id22 = \"GTG GGC ATC GGG ACG CCG ATT TTC TCC TAT GGC GGG GGT GCA GGG CAT GTT CCC GAG TAT TTC\"\n",
    "id23 = \"CCC GAC AGC GTA TCC ATT CCC ATT ACC TGT TGC TTC AAT GTC ATC AAC CGT AAA ATT CCT ATC CAA CGC TTG GAA TCC TAT ACA CGC ATC ACG AAT ATT CAA TGC CCG AAG GAG GCT GTC ATT TTC AAG ACC AAA CGT GGA AAA GAG GTA TGT GCG GAC CCG AAG GAA CGC TGG GTT CGC GAT TCC ATG AAA CAT TTG GAC CAA ATT TTC CAG AAT CTG AAG CCG\"\n",
    "id25 = \"AAG ACA AAA AAG AAA TTA TTG AAA AAG ACC\"\n",
    "id26 = \"TGGTATGTACGCAAATGCGCTAATAAACTGGGAACATGTCGCAAGACCTGCCGTAAGGGGGAATATCAGACAGACCCAGCCACGGGCAAGTGCTCTATCGGGAAGCTTTGTTGCATCTTGGATTTGAAGCTGGCAGGTCAATGTGGTGGAGCCGACGGCAACCAAGCGGCTGCGGGCACACAAGCAGCCGGAGGGACACGCGCTGCCGGGGGCACCCAGGGTACGGGAGGAACAGGCGCAACTGGAGCGGCAGCCACAACCGCAGCGCCC\"\n",
    "id27 = \"GGG CGT CCT AAC CCG GTG AAC AAT AAG CCG ACC CCA CAT CCG CGC TTG\"\n",
    "id28 = \"GATTCCCATGAAGAACGTCGCCAAGGACGCCACGGACATCATGAATACGGTCGTAAGTTCCATGAGAAACATCACTCACATCGTGGGTAT\"\n",
    "id29 = \"GGT TCA AAG AAA CCA GTC CCT ATT ATT TAT TGT AAT CGT CGT ACG GGC AAA TGT CAG CGC ATG\"\n",
    "id30 = \"TACAAACAATGCCACAAAAAGGGGGGACACTGCTTCCCCAAAGAAAAGATTTGTCTACCGCCCTCCTCAGATTTCGGAAAAATGGATTGTCGCTGGCGCTGGAAGTGTTGTAAGAAAGGTTCGGGG\"\n",
    "id32 = \"CGC CGC TGG TGG CGC TTC\"\n",
    "id33 = \"ACC TGT GAA TCC CCC AGC CAT AAG TTC AAA GGA CCT TGT GCA ACT AAC CGT AAT TGC GAA TCT\"\n",
    "id35 = \"TTC TTT CAC CAC ATC TTT CGT GGA ATC GTT CAC GTA GGA AAG ACA ATC CAC AAA TTA GTC ACG GGG\"\n",
    "id36 = \"CGCGGTGGACGCCTTTGCTACTGCCGTCGTCGTTTTTGCATTTGTGTA\"\n",
    "id38 = \"GGA TTA CCA GTG TGT GGT GAA ACC TGT TTC GGC GGG ACT TGC AAC ACA CCC GGT TGC TCT TGC ACC TGG CCA ATT TGT ACG CGT GAT\"\n",
    "id39 = \"ATT CTT CCC TGG AAG TGG CCC TGG TGG CCC TGG CGT CGT\"\n",
    "id40 = \"GAA GAA GAA TCA GAG GTC GCA CAC CTT CGT GTT CGT CGT GGG TTC GGT TGT CCA CTT AAT CAA GGA GCG TGT CAC CGT CAC TGC CGC TCG ATT CGT CGT CGT GGA GGA TAC TGT TCT GGT ATT ATC AAG CAG ACC TGC ACA TGC TAC CGC AAC\"\n",
    "id41 = \"CAC GGA GTG TCG GGA CAC GGC CAG CAC GGC GTG CAC GGG\"\n",
    "\n",
    "# just a pretty inefficient way to put all the amps in the same list and then later, dictionary\n",
    "amplistspaces = [id14, id15, id16, id17, id18, id19, id20, id21, id22, id23, id25, id26, id27, id28, id29, id30, id32, id33, id35,\n",
    "       id36, id38, id39, id40, id41]\n",
    "amplist = []\n",
    "for amp in amplistspaces:\n",
    "    amplist.append(amp.replace(' ', ''))\n",
    "\n",
    "amp_dict = {'id14': amplist[0], 'id15': amplist[1], 'id16': amplist[2], 'id17': amplist[3], 'id18': amplist[4], \n",
    "            'id19': amplist[5], 'id20': amplist[6], \n",
    "           'id21': amplist[7], 'id22': amplist[8], 'id23': amplist[9], 'id25': amplist[10], 'id26': amplist[11], \n",
    "            'id27': amplist[12], 'id28': amplist[13], \n",
    "           'id29': amplist[14], 'id30': amplist[15], 'id32': amplist[16], 'id33': amplist[17], 'id35': amplist[18], \n",
    "            'id36': amplist[19], 'id38': amplist[20], \n",
    "           'id39': amplist[21], 'id40': amplist[22], 'id41': amplist[23]}\n",
    "\n",
    "### Making additional protein domain dictionary\n",
    "magainin = \"GATGATGCCGAAGCTGTCGGCCCCGAGGCGTTCGCGGACGAAGATTTAGATGAA\"\n",
    "apd_dict = {'magainin': magainin}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for illegal sites\n",
    "### check coding strand linkers for cut sites\n",
    "### check complementary strand linkers for cut sites\n",
    "### check coding strand cleavable linkers for cut sites\n",
    "### check complementary strand cleavable linkers for cut sites\n",
    "### check coding strand amps for cut sites\n",
    "### check complementary strand amps for cut sites\n",
    "### check coding strand adps for cut sites\n",
    "### check complementary strand adps for cut sites\n",
    "### check linkers for enterokinase proteolytic site\n",
    "### check amps for enterokinase proteolytic site \n",
    "### check adps for enterokinase proteolytic site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no restriction sites in linkers\n",
      "There are no restriction sites in linker complements\n",
      "There are no restriction sites in cleavable linkers\n",
      "There are no restriction sites in cleavable linker complements\n",
      "There are no restriction sites in amps\n",
      "There are no restriction sites in amp complements\n",
      "There are no restriction sites in additional protein domains\n",
      "There are no restriction sites in additional protein domain complements\n",
      "There are no proteolytic sites in linkers\n",
      "There are no proteolytic sites in amps\n",
      "There are no proteolytic sites in additional protein domains\n"
     ]
    }
   ],
   "source": [
    "### check coding strand linkers for cut sites\n",
    "linkerdigestlist = fraginDNA(restriction_dict, linker_dict)\n",
    "if len(linkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in linkers\")\n",
    "else:\n",
    "    for i in range(len(linkerdigestlist[0])):\n",
    "        print(linkerdigestlist[0][i] + \" is in \" + linkerdigestlist[1][i] + \" at index \" + str(linkerdigestlist[2][i]))\n",
    "\n",
    "### check complementary strand linkers for cut sites\n",
    "comp_linker_dict = {}\n",
    "for linker in linker_dict:\n",
    "    comp_linker_dict[linker] = flip(complementary(linker_dict[linker]))\n",
    "complinkerdigestlist = fraginDNA(restriction_dict, comp_linker_dict)\n",
    "if len(complinkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in linker complements\")\n",
    "else:\n",
    "    for i in range(len(linkerdigestlist[0])):\n",
    "        print(complinkerdigestlist[0][i] + \" is in \" + complinkerdigestlist[1][i] + \" at index \" + \n",
    "              str(complinkerdigestlist[2][i]))\n",
    "\n",
    "### check coding strand cleavable linkers for cut sites\n",
    "clinkerdigestlist = fraginDNA(restriction_dict, clinker_dict)\n",
    "if len(clinkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in cleavable linkers\")\n",
    "else:\n",
    "    for i in range(len(clinkerdigestlist[0])):\n",
    "        print(clinkerdigestlist[0][i] + \" is in \" + clinkerdigestlist[1][i] + \" at index \" + str(clinkerdigestlist[2][i]))\n",
    "\n",
    "### check complementary strand cleavable linkers for cut sites\n",
    "comp_clinker_dict = {}\n",
    "for clinker in clinker_dict:\n",
    "    comp_clinker_dict[clinker] = flip(complementary(clinker_dict[clinker]))\n",
    "compclinkerdigestlist = fraginDNA(restriction_dict, comp_clinker_dict)\n",
    "if len(compclinkerdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in cleavable linker complements\")\n",
    "else:\n",
    "    for i in range(len(compclinkerdigestlist[0])):\n",
    "        print(compclinkerdigestlist[0][i] + \" is in \" + compclinkerdigestlist[1][i] + \" at index \" + \n",
    "              str(compclinkerdigestlist[2][i]))\n",
    "\n",
    "### check coding strand amps for cut sites\n",
    "ampdigestlist = fraginDNA(restriction_dict, amp_dict)\n",
    "if len(ampdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in amps\")\n",
    "else:\n",
    "    for i in range(len(ampdigestlist[0])):\n",
    "        print(ampdigestlist[0][i] + \" is in \" + ampdigestlist[1][i] + \" at index \" + str(ampdigestlist[2][i]))\n",
    "\n",
    "### check complementary strand amps for cut sites\n",
    "comp_amp_dict = {}\n",
    "for amp in amp_dict:\n",
    "    comp_amp_dict[amp] = flip(complementary(amp_dict[amp]))\n",
    "compampdigestlist = fraginDNA(restriction_dict, comp_amp_dict)\n",
    "if len(compampdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in amp complements\")\n",
    "else:\n",
    "    for i in range(len(compampdigestlist[0])):\n",
    "        print(compampdigestlist[0][i] + \" is in \" + compampdigestlist[1][i] + \" at index \" + str(compampdigestlist[2][i]))\n",
    "\n",
    "### check coding strand adps for cut sites\n",
    "adpdigestlist = fraginDNA(restriction_dict, apd_dict)\n",
    "if len(adpdigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in additional protein domains\")\n",
    "else:\n",
    "    for i in range(len(adpdigestlist[0])):\n",
    "        print(adpdigestlist[0][i] + \" is in \" + adpdigestlist[1][i] + \" at index \" + str(adpdigestlist[2][i]))\n",
    "\n",
    "### check complementary strand adps for cut sites\n",
    "comp_apd_dict = {}\n",
    "for apd in apd_dict:\n",
    "    comp_apd_dict[apd] = flip(complementary(apd_dict[apd]))\n",
    "compapddigestlist = fraginDNA(restriction_dict, comp_apd_dict)\n",
    "if len(compapddigestlist[0]) < 1:\n",
    "    print(\"There are no restriction sites in additional protein domain complements\")\n",
    "else:\n",
    "    for i in range(len(compapddigestlist[0])):\n",
    "        print(compapddigestlist[0][i] + \" is in \" + compapddigestlist[1][i] + \" at index \" + str(compapddigestlist[2][i]))\n",
    "        \n",
    "### check linkers for enterokinase proteolytic site\n",
    "aa_linker_dict = {}\n",
    "for linker in linker_dict:\n",
    "    aa_linker_dict[linker] = translate(linker_dict[linker])\n",
    "linkerprotdigestlist = aainprot(proteolytic_dict, aa_linker_dict)\n",
    "if len(linkerprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in linkers\")\n",
    "else:\n",
    "    for i in range(len(linkerprotdigestlist[0])):\n",
    "        print(linkerprotdigestlist[0][i] + \" is in \" + linkerprotdigestlist[1][i] + \" at index \" + \n",
    "             str(linkerprotdigestlist[2][i]))\n",
    "\n",
    "### check amps for enterokinase proteolytic site \n",
    "aa_amp_dict = {}\n",
    "for amp in amp_dict:\n",
    "    aa_amp_dict[amp] = translate(amp_dict[amp])\n",
    "ampprotdigestlist = aainprot(proteolytic_dict, aa_amp_dict)\n",
    "if len(ampprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in amps\")\n",
    "else:\n",
    "    for i in range(len(ampprotdigestlist[0])):\n",
    "        print(ampprotdigestlist[0][i] + \" is in \" + ampprotdigestlist[1][i] + \" at index \" +\n",
    "             str(ampprotdigestlist[2][i]))\n",
    "\n",
    "### check adps for enterokinase proteolytic site\n",
    "aa_apd_dict = {}\n",
    "for apd in apd_dict:\n",
    "    aa_apd_dict[apd] = translate(apd_dict[apd])\n",
    "apdprotdigestlist = aainprot(proteolytic_dict, aa_apd_dict)\n",
    "if len(apdprotdigestlist[0]) < 1:\n",
    "    print(\"There are no proteolytic sites in additional protein domains\")\n",
    "else:\n",
    "    for i in range(len(apdprotdigestlist[0])):\n",
    "        print(apdprotdigestlist[0][i] + \" is in \" + apdprotdigestlist[1][i] + \" at index \" +\n",
    "             str(apdprotdigestlist[2][i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the library\n",
    "\n",
    "Go the following link for a more detailed explanation of our library assembly method:\n",
    "https://docs.google.com/presentation/d/1uTLnbKfePm92kEpmq7wKOC5tkWJBngjobffdjJsNSyE/edit#slide=id.g1e74bcb382_0_120\n",
    "\n",
    "Inside of a destination vector plasmid, we will account for a linear piece of DNA with the following positions, labeled numerically:\n",
    "N-terminus - (1) protective payload - (2) cleavable linker - (3) N payload - (4) linker - (5) polymer - (6) linker - \n",
    "             (7) C payload - (8) cleavable linker - (9) protective payload - C-terminus\n",
    "At each of the dashses, there needs to be a unique 4 bp scarring sequence that will be the overhang after digestion by BbsI to create a Level 0 part. Because we need to avoid frameshifts, I will treat each of these scarring sequences as being 6 bp, even though there will only be a 4 bp overhang after digestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subparts for our final ultramers\n",
    "### Cut sites\n",
    "### Start and stop codons\n",
    "### BbsI and BbsI'\n",
    "### NN sequences (two base buffer)\n",
    "### Main part sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cut sites\n",
    "# cut sites are in order of position\n",
    "# (e.g.) first entry is between destination vector and (1), second entry between (1) and (2), and so on\n",
    "cutsitetable = ['aagagg', 'ggctct', 'tctggc', 'tcttct', 'ggaatg', 'aggtca', 'ggcgga', 'agcagc', 'ggcagc', 'actaaa']\n",
    "\n",
    "### Start and stop codons\n",
    "start = \"atg\"\n",
    "stop = \"taa\"\n",
    "\n",
    "### BbsI and BbsI'\n",
    "BbsI = \"GAAGAC\"\n",
    "BbsIprime = \"GTCTTC\"\n",
    "\n",
    "### NN sequences (two base buffer)\n",
    "NN = \"aa\"\n",
    "\n",
    "### Main part sequences\n",
    "linker_dict\n",
    "clinker_dict\n",
    "amp_dict\n",
    "apd_dict\n",
    "\n",
    "print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our list of ultramers to be ordered\n",
    "### Position 1\n",
    "### Position 2\n",
    "### Position 3\n",
    "### Position 4\n",
    "\n",
    "### Position 6\n",
    "### Position 7\n",
    "### Position 8\n",
    "### Position 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position 1\n",
    "apd_pos1 = {}\n",
    "for apd in apd_dict:\n",
    "    apd_pos1[apd] = (BbsI + cutsitetable[0] + start + apd_dict[apd] + cutsitetable[1] + BbsIprime).upper()\n",
    "\n",
    "# Position 2\n",
    "clinker_pos2 = {}\n",
    "for clinker in clinker_dict:\n",
    "    clinker_pos2[clinker] = (BbsI + NN + cutsitetable[1] + clinker_dict[clinker] + cutsitetable[2] + NN + BbsIprime).upper()\n",
    "\n",
    "# Position 3\n",
    "payload_pos3 = {}\n",
    "for payload in amp_dict:\n",
    "    payload_pos3[payload] = (BbsI + cutsitetable[2] + amp_dict[payload] + cutsitetable[3] + BbsIprime).upper()\n",
    "\n",
    "# Position 4\n",
    "linker_pos4 = {}\n",
    "for linker in linker_dict:\n",
    "    linker_pos4[linker] = (BbsI + NN + cutsitetable[3] + linker_dict[linker] + cutsitetable[4] + NN + BbsIprime).upper()\n",
    "\n",
    "# Position 6\n",
    "linker_pos6 = {}\n",
    "for linker in linker_dict:\n",
    "    linker_pos6[linker] = (BbsI + NN + cutsitetable[5] + linker_dict[linker] + cutsitetable[6] + NN + BbsIprime).upper()\n",
    "\n",
    "# Position 7\n",
    "payload_pos7 = {}\n",
    "for payload in amp_dict:\n",
    "    payload_pos7[payload] = (BbsI + cutsitetable[6] + amp_dict[payload] + cutsitetable[7] + BbsIprime).upper()\n",
    "\n",
    "# Position 8\n",
    "clinker_pos8 = {}\n",
    "for clinker in clinker_dict:\n",
    "    clinker_pos8[clinker] = (BbsI + NN + cutsitetable[7] + clinker_dict[clinker] + cutsitetable[8] + NN + BbsIprime).upper()\n",
    "\n",
    "# Position 9\n",
    "apd_pos9 = {}\n",
    "for apd in apd_dict:\n",
    "    apd_pos9[apd] = (BbsI + cutsitetable[8] + apd_dict[apd] + (2*stop) + cutsitetable[9] + BbsIprime).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting these dicts into csv form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w') as output:\n",
    "    writer = csv.writer(output)\n",
    "    for key, value in apd_pos1.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in clinker_pos2.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in payload_pos3.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in linker_pos4.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in linker_pos6.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in payload_pos7.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in clinker_pos8.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])\n",
    "    for key, value in apd_pos9.items():\n",
    "        writer.writerow([key, value])\n",
    "    writer.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
